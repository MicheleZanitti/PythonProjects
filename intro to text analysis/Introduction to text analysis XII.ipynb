{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to text analysis XII  ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Revision 2019*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding models ###\n",
    "\n",
    "Word embedding models are a method to simplify the tfidf matrices transforming them into dense representation os words. Embedding (i.e. dimensionaly reduction) the large sparse matrix into a smaller dense matrix. The data are built with a vectorization in mind.\n",
    "\n",
    "king + woman == queen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec,KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfiles = sorted(glob.glob(\"en-2/*json\")) ## notice the usage of glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**read file for a test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorpus(text,corpus):\n",
    "    text = text.lower()\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for s in sentences:\n",
    "        corpus.append(nltk.word_tokenize(s))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the corpus has the form:\n",
    "\n",
    "    [[word_a,word_b,word_c], [word_a1,word_b1,word_c1,]]\n",
    "\n",
    "list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for enfile in enfiles:\n",
    "    js = json.loads(open(enfile,\"r\").read())\n",
    "    cnt = js['content']\n",
    "    cntt = js['title']\n",
    "    cnts = js['summary']\n",
    "    corpus = createCorpus(cnt,corpus)    \n",
    "    corpus = createCorpus(cntt,corpus)    \n",
    "    corpus = createCorpus(cnts,corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166743"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**usage of the Word2Vec DL (deep learning) model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.9 s, sys: 157 ms, total: 57 s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(corpus,size=50, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most interesting usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('refining', 0.8377496600151062),\n",
       " ('coal', 0.836725652217865),\n",
       " ('sugar', 0.8028675317764282),\n",
       " ('biodiesel', 0.7810451984405518),\n",
       " ('oil', 0.7507070899009705),\n",
       " ('wood', 0.7373133301734924),\n",
       " ('oils', 0.7360048890113831),\n",
       " ('crude', 0.7216693758964539),\n",
       " ('mineral', 0.7194509506225586),\n",
       " ('metallurgy', 0.7183658480644226)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('petroleum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the resuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ModelWiki_english.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
